{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM-GAN Training: Missing Modality Imputation on IXI Dataset\n",
    "\n",
    "This notebook implements **Phase 2** of the 2-phase MM-GAN training pipeline for brain MRI missing modality imputation.\n",
    "\n",
    "**System Overview:**\n",
    "- **Phase 1** (local): Data download, preprocessing, and slice extraction from IXI brain MRI volumes.\n",
    "- **Phase 2** (this notebook, Kaggle GPU): Train MM-GAN on the pre-extracted slices with GPU acceleration.\n",
    "\n",
    "**Key Features:**\n",
    "- Supports **resumable training** across 2-hour Kaggle session chunks â€” saves checkpoints before timeout and auto-resumes on re-run.\n",
    "- Trains a UNet Generator + PatchGAN Discriminator on 3 modalities: **T1, T2, PD**.\n",
    "- Uses **implicit conditioning** and **curriculum learning** for stable training.\n",
    "\n",
    "**Run this notebook twice:**\n",
    "1. `EXPERIMENT_NAME = \"baseline\"` with baseline preprocessed data.\n",
    "2. `EXPERIMENT_NAME = \"optimized\"` with N4 bias-corrected (optimized) data.\n",
    "\n",
    "Then compare the results to evaluate the impact of preprocessing quality on imputation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (Kaggle already has PyTorch, torchvision, numpy, etc.)\n",
    "!pip install -q scikit-image tensorboard tqdm\n",
    "\n",
    "import os, sys, time, random, json, glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Change `EXPERIMENT_NAME` and `DATA_PATH` for each run:\n",
    "- **Session 1**: Starts fresh training from epoch 0.\n",
    "- **Subsequent sessions**: Automatically resumes from the latest checkpoint.\n",
    "\n",
    "| Run | `EXPERIMENT_NAME` | `DATA_PATH` |\n",
    "|-----|-------------------|--------------|\n",
    "| 1   | `\"baseline\"`      | Path to baseline slices dataset |\n",
    "| 2   | `\"optimized\"`     | Path to N4 bias-corrected slices dataset |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - Change these for each run\n",
    "# ============================================================\n",
    "EXPERIMENT_NAME = \"baseline\"  # \"baseline\" or \"optimized\"\n",
    "DATA_PATH = \"/kaggle/input/ixi-slices-baseline\"  # Update with your dataset name\n",
    "\n",
    "# Training hyperparameters (MUST be identical for both experiments)\n",
    "N_EPOCHS = 60\n",
    "BATCH_SIZE = 8\n",
    "LR_G = 2e-4\n",
    "LR_D = 2e-4\n",
    "LAMBDA_PIXEL = 0.9\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999\n",
    "SEED = 42\n",
    "IMG_SIZE = 256\n",
    "IN_CHANNELS = 3\n",
    "IMPUTE_TYPE = \"zeros\"\n",
    "USE_IC = True           # Implicit conditioning\n",
    "USE_CURRICULUM = True   # Curriculum learning\n",
    "\n",
    "# Session management\n",
    "SAVE_INTERVAL = 5       # Save checkpoint every N epochs\n",
    "VAL_INTERVAL = 2        # Validate every N epochs\n",
    "MAX_SESSION_TIME = 6600  # 1h50m safety margin (Kaggle limit is 2h = 7200s)\n",
    "\n",
    "# Paths\n",
    "CHECKPOINT_DIR = f\"/kaggle/working/checkpoints/{EXPERIMENT_NAME}\"\n",
    "LOG_DIR = f\"/kaggle/working/logs/{EXPERIMENT_NAME}\"\n",
    "RESULTS_DIR = f\"/kaggle/working/results/{EXPERIMENT_NAME}\"\n",
    "\n",
    "for d in [CHECKPOINT_DIR, LOG_DIR, RESULTS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Checkpoint dir: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MM-GAN Architecture\n",
    "\n",
    "**Generator**: UNet with 8 encoder blocks and 7 decoder blocks with skip connections. Uses InstanceNorm and ReLU final activation (data is [0,1] normalized).\n",
    "\n",
    "**Discriminator**: PatchGAN with 4 downsampling blocks. Outputs per-patch real/fake predictions.\n",
    "\n",
    "Adapted for 3 modalities (T1, T2, PD) from the original 4-modality BRATS setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MM-GAN Model Architecture\n",
    "# Adapted for IXI Dataset (3 modalities: T1, T2, PD)\n",
    "# Based on: https://github.com/trane293/mm-gan\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    \"\"\"Initialize weights using normal distribution.\"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "# ---- U-Net Generator ----\n",
    "\n",
    "class UNetDown(nn.Module):\n",
    "    \"\"\"Encoder block: Conv -> [InstanceNorm] -> LeakyReLU -> [Dropout]\"\"\"\n",
    "\n",
    "    def __init__(self, in_size, out_size, normalize=True, dropout=0.0):\n",
    "        super().__init__()\n",
    "        layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_size))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UNetUp(nn.Module):\n",
    "    \"\"\"Decoder block: ConvTranspose -> InstanceNorm -> ReLU -> [Dropout] + skip\"\"\"\n",
    "\n",
    "    def __init__(self, in_size, out_size, dropout=0.0):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat((x, skip_input), 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GeneratorUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet Generator with skip connections.\n",
    "    For IXI: in_channels=3 (T1, T2, PD), out_channels=3\n",
    "    Input size: (B, 3, 256, 256) -> Output: (B, 3, 256, 256)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.down1 = UNetDown(in_channels, 64, normalize=False)\n",
    "        self.down2 = UNetDown(64, 128)\n",
    "        self.down3 = UNetDown(128, 256)\n",
    "        self.down4 = UNetDown(256, 512, dropout=0.2)\n",
    "        self.down5 = UNetDown(512, 512, dropout=0.2)\n",
    "        self.down6 = UNetDown(512, 512, dropout=0.2)\n",
    "        self.down7 = UNetDown(512, 512, dropout=0.2)\n",
    "        self.down8 = UNetDown(512, 512, normalize=False, dropout=0.2)\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = UNetUp(512, 512, dropout=0.2)\n",
    "        self.up2 = UNetUp(1024, 512, dropout=0.2)\n",
    "        self.up3 = UNetUp(1024, 512, dropout=0.2)\n",
    "        self.up4 = UNetUp(1024, 512, dropout=0.2)\n",
    "        self.up5 = UNetUp(1024, 256)\n",
    "        self.up6 = UNetUp(512, 128)\n",
    "        self.up7 = UNetUp(256, 64)\n",
    "\n",
    "        # Final layer with ReLU (output in [0, inf), data is [0,1] normalized)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(128, out_channels, 4, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        d7 = self.down7(d6)\n",
    "        d8 = self.down8(d7)  # Bottleneck\n",
    "\n",
    "        # Decoder path with skip connections\n",
    "        u1 = self.up1(d8, d7)\n",
    "        u2 = self.up2(u1, d6)\n",
    "        u3 = self.up3(u2, d5)\n",
    "        u4 = self.up4(u3, d4)\n",
    "        u5 = self.up5(u4, d3)\n",
    "        u6 = self.up6(u5, d2)\n",
    "        u7 = self.up7(u6, d1)\n",
    "\n",
    "        return self.final(u7)\n",
    "\n",
    "\n",
    "# ---- PatchGAN Discriminator ----\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    PatchGAN Discriminator.\n",
    "    For IXI: in_channels=3 (receives concat of real/fake + condition = 6 channels)\n",
    "    Output: (B, out_channels, H/16, W/16) patch predictions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, normalization=True):\n",
    "            \"\"\"Downsampling block: Conv -> [InstanceNorm] -> LeakyReLU\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        # Input: (in_channels * 2) because we concat img_A and img_B\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(in_channels * 2, 64, normalization=False),\n",
    "            *discriminator_block(64, 128),\n",
    "            *discriminator_block(128, 256),\n",
    "            *discriminator_block(256, 512),\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
    "            nn.Conv2d(512, out_channels, 4, padding=1, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, img_A, img_B):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_A: Generated/real image (B, C, H, W)\n",
    "            img_B: Condition image (B, C, H, W)\n",
    "        Returns:\n",
    "            Patch predictions (B, out_channels, H/16, W/16)\n",
    "        \"\"\"\n",
    "        img_input = torch.cat((img_A, img_B), 1)\n",
    "        return self.model(img_input)\n",
    "\n",
    "\n",
    "# ---- Missing Modality Logic ----\n",
    "\n",
    "# All possible missing modality scenarios for 3 modalities (T1, T2, PD)\n",
    "# 0 = missing, 1 = available\n",
    "# Sorted by difficulty: fewer available = harder (first)\n",
    "ALL_SCENARIOS_3MOD = [\n",
    "    [1, 0, 0],  # Only T1 available       (hardest: 2 missing)\n",
    "    [0, 1, 0],  # Only T2 available\n",
    "    [0, 0, 1],  # Only PD available\n",
    "    [1, 1, 0],  # T1+T2 available          (medium: 1 missing)\n",
    "    [1, 0, 1],  # T1+PD available\n",
    "    [0, 1, 1],  # T2+PD available          (easiest: 1 missing)\n",
    "]\n",
    "\n",
    "# Modality names (indexed)\n",
    "MODALITY_NAMES = [\"T1\", \"T2\", \"PD\"]\n",
    "\n",
    "\n",
    "def get_curriculum_scenarios(epoch, total_epochs):\n",
    "    \"\"\"\n",
    "    Curriculum learning strategy for 3-modality setup.\n",
    "    Starts with easy scenarios (1 missing) and gradually adds harder ones.\n",
    "\n",
    "    Returns: (low_idx, high_idx) range into ALL_SCENARIOS_3MOD\n",
    "    \"\"\"\n",
    "    progress = epoch / max(total_epochs, 1)\n",
    "\n",
    "    if progress <= 0.3:\n",
    "        # First 30%: easy scenarios only (1 missing modality)\n",
    "        return 3, 6\n",
    "    elif progress <= 0.7:\n",
    "        # 30-70%: all scenarios\n",
    "        return 0, 6\n",
    "    else:\n",
    "        # 70%+: all scenarios (full difficulty)\n",
    "        return 0, 6\n",
    "\n",
    "\n",
    "def impute_missing(x_real, scenario, impute_type=\"zeros\"):\n",
    "    \"\"\"\n",
    "    Replace missing modality channels with imputation values.\n",
    "\n",
    "    Args:\n",
    "        x_real: (B, C, H, W) tensor of real images\n",
    "        scenario: list of 0/1 indicating missing/available\n",
    "        impute_type: 'zeros', 'noise', or 'average'\n",
    "\n",
    "    Returns:\n",
    "        x_imputed: tensor with missing channels replaced\n",
    "    \"\"\"\n",
    "    x_imputed = x_real.clone()\n",
    "    B, C, H, W = x_imputed.shape\n",
    "\n",
    "    if impute_type == \"average\":\n",
    "        avail_idx = [i for i, s in enumerate(scenario) if s == 1]\n",
    "        if avail_idx:\n",
    "            avg = torch.mean(x_real[:, avail_idx, ...], dim=1)\n",
    "        else:\n",
    "            avg = torch.zeros(B, H, W, device=x_real.device)\n",
    "\n",
    "    for idx, available in enumerate(scenario):\n",
    "        if available == 0:\n",
    "            if impute_type == \"zeros\":\n",
    "                x_imputed[:, idx, ...] = 0.0\n",
    "            elif impute_type == \"noise\":\n",
    "                x_imputed[:, idx, ...] = torch.randn(B, H, W, device=x_real.device)\n",
    "            elif impute_type == \"average\":\n",
    "                x_imputed[:, idx, ...] = avg\n",
    "\n",
    "    return x_imputed\n",
    "\n",
    "\n",
    "def impute_reals_into_fake(x_input, fake_x, scenario):\n",
    "    \"\"\"\n",
    "    Implicit conditioning: copy real (available) modalities back into\n",
    "    the generator output so loss is only on synthesized channels.\n",
    "\n",
    "    Args:\n",
    "        x_input: (B, C, H, W) original input with real available channels\n",
    "        fake_x: (B, C, H, W) generator output\n",
    "        scenario: list of 0/1 indicating missing/available\n",
    "    Returns:\n",
    "        fake_x with available channels replaced by real values\n",
    "    \"\"\"\n",
    "    result = fake_x.clone()\n",
    "    for idx, available in enumerate(scenario):\n",
    "        if available == 1:\n",
    "            result[:, idx, ...] = x_input[:, idx, ...].clone()\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_missing_loss(fake_x, real_x, scenario, loss_fn):\n",
    "    \"\"\"\n",
    "    Compute loss ONLY on missing modality channels (for implicit conditioning).\n",
    "\n",
    "    Args:\n",
    "        fake_x: Generator output (B, C, H, W)\n",
    "        real_x: Ground truth (B, C, H, W)\n",
    "        scenario: list of 0/1\n",
    "        loss_fn: loss function (e.g., nn.L1Loss())\n",
    "\n",
    "    Returns:\n",
    "        Loss value averaged over missing channels\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    for idx, available in enumerate(scenario):\n",
    "        if available == 0:\n",
    "            losses.append(loss_fn(fake_x[:, idx, ...], real_x[:, idx, ...]))\n",
    "\n",
    "    if losses:\n",
    "        return sum(losses) / len(losses)\n",
    "    return torch.tensor(0.0, device=fake_x.device)\n",
    "\n",
    "\n",
    "print(\"Model architecture loaded.\")\n",
    "print(f\"  Scenarios: {len(ALL_SCENARIOS_3MOD)}\")\n",
    "print(f\"  Modalities: {MODALITY_NAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IXI Slice Dataset\n",
    "\n",
    "Loads pre-extracted `.npy` slices with shape `(3, H, W)` = `[T1, T2, PD]`.\n",
    "\n",
    "Data is already normalized to `[0, 1]` by the Phase 1 extraction pipeline. Expects directory structure:\n",
    "```\n",
    "DATA_PATH/\n",
    "  train/\n",
    "    subject001_slice050.npy\n",
    "    ...\n",
    "  val/\n",
    "    ...\n",
    "  test/\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IXI Dataset Loader\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "class IXISliceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for loading pre-extracted IXI axial slices.\n",
    "    Each .npy file is shape (3, H, W) with channels [T1, T2, PD].\n",
    "    Data is already normalized to [0, 1] by the extraction pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, split=\"train\", target_size=(256, 256), augment=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: Root directory containing split subdirs (train/val/test)\n",
    "            split: 'train', 'val', or 'test'\n",
    "            target_size: Resize slices to this size (H, W)\n",
    "            augment: Apply data augmentation (horizontal flip)\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir) / split\n",
    "        self.target_size = target_size\n",
    "        self.augment = augment\n",
    "\n",
    "        # Collect all .npy files\n",
    "        if not self.data_dir.exists():\n",
    "            raise FileNotFoundError(f\"Split directory not found: {self.data_dir}\")\n",
    "\n",
    "        self.file_list = sorted(list(self.data_dir.glob(\"*.npy\")))\n",
    "\n",
    "        if len(self.file_list) == 0:\n",
    "            raise RuntimeError(f\"No .npy files found in {self.data_dir}\")\n",
    "\n",
    "        print(f\"[IXISliceDataset] {split}: {len(self.file_list)} slices from {self.data_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            dict with:\n",
    "                image: (3, H, W) float32 tensor, channels = [T1, T2, PD]\n",
    "                filename: str, name of the .npy file (for tracking)\n",
    "        \"\"\"\n",
    "        filepath = self.file_list[idx]\n",
    "        data = np.load(filepath).astype(np.float32)  # (3, H, W)\n",
    "\n",
    "        # Convert to tensor\n",
    "        image = torch.from_numpy(data)\n",
    "\n",
    "        # Resize if needed\n",
    "        if self.target_size is not None:\n",
    "            h, w = image.shape[1], image.shape[2]\n",
    "            if (h, w) != self.target_size:\n",
    "                image = TF.resize(\n",
    "                    image, list(self.target_size),\n",
    "                    interpolation=TF.InterpolationMode.BILINEAR,\n",
    "                    antialias=True,\n",
    "                )\n",
    "\n",
    "        # Augmentation\n",
    "        if self.augment and torch.rand(1).item() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"filename\": filepath.stem,\n",
    "        }\n",
    "\n",
    "\n",
    "def create_dataloaders(\n",
    "    data_dir,\n",
    "    batch_size=8,\n",
    "    target_size=(256, 256),\n",
    "    num_workers=2,\n",
    "    augment_train=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create train, val, test DataLoaders.\n",
    "\n",
    "    Args:\n",
    "        data_dir: Root directory with train/val/test subdirs\n",
    "        batch_size: Batch size\n",
    "        target_size: Resize to (H, W)\n",
    "        num_workers: DataLoader workers\n",
    "        augment_train: Apply augmentation to training set\n",
    "\n",
    "    Returns:\n",
    "        dict of {'train': DataLoader, 'val': DataLoader, 'test': DataLoader}\n",
    "    \"\"\"\n",
    "    loaders = {}\n",
    "\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        split_dir = Path(data_dir) / split\n",
    "        if not split_dir.exists():\n",
    "            print(f\"[WARN] Split directory missing: {split_dir}\")\n",
    "            continue\n",
    "\n",
    "        augment = augment_train if split == \"train\" else False\n",
    "        shuffle = split == \"train\"\n",
    "\n",
    "        dataset = IXISliceDataset(\n",
    "            data_dir=data_dir,\n",
    "            split=split,\n",
    "            target_size=target_size,\n",
    "            augment=augment,\n",
    "        )\n",
    "\n",
    "        loaders[split] = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=(split == \"train\"),\n",
    "        )\n",
    "\n",
    "    return loaders\n",
    "\n",
    "\n",
    "print(\"Dataset classes loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics (PSNR, SSIM) and Checkpoint Management\n",
    "\n",
    "- **Metrics**: NumPy-based (for final evaluation) and PyTorch-based (for training loop) implementations of PSNR and SSIM.\n",
    "- **Checkpoints**: Saves full training state (model, optimizer, scheduler, epoch, metrics, RNG states) for seamless resume across Kaggle sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Metrics: PSNR and SSIM\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# --- NumPy-based (for final evaluation) ---\n",
    "\n",
    "def psnr_numpy(pred, gt, data_range=1.0):\n",
    "    \"\"\"\n",
    "    Compute PSNR between two images.\n",
    "    PSNR = 10 * log10(MAX^2 / MSE)\n",
    "    \"\"\"\n",
    "    mse = np.mean((pred.astype(np.float64) - gt.astype(np.float64)) ** 2)\n",
    "    if mse < 1e-10:\n",
    "        return 100.0\n",
    "    return 10.0 * np.log10(data_range**2 / mse)\n",
    "\n",
    "\n",
    "def ssim_numpy(pred, gt, data_range=1.0):\n",
    "    \"\"\"Compute SSIM between two 2D images using scikit-image.\"\"\"\n",
    "    from skimage.metrics import structural_similarity\n",
    "    return structural_similarity(pred, gt, data_range=data_range)\n",
    "\n",
    "\n",
    "def compute_metrics_batch(pred_batch, gt_batch, data_range=1.0):\n",
    "    \"\"\"\n",
    "    Compute PSNR and SSIM for a batch of images.\n",
    "\n",
    "    Args:\n",
    "        pred_batch: (B, C, H, W) numpy array\n",
    "        gt_batch: (B, C, H, W) numpy array\n",
    "        data_range: max pixel value\n",
    "\n",
    "    Returns:\n",
    "        dict with lists of per-sample PSNR and SSIM values\n",
    "    \"\"\"\n",
    "    B, C, H, W = pred_batch.shape\n",
    "    psnr_vals = []\n",
    "    ssim_vals = []\n",
    "\n",
    "    for b in range(B):\n",
    "        p_list = []\n",
    "        s_list = []\n",
    "        for c in range(C):\n",
    "            p_list.append(psnr_numpy(pred_batch[b, c], gt_batch[b, c], data_range))\n",
    "            s_list.append(ssim_numpy(pred_batch[b, c], gt_batch[b, c], data_range))\n",
    "        psnr_vals.append(np.mean(p_list))\n",
    "        ssim_vals.append(np.mean(s_list))\n",
    "\n",
    "    return {\"psnr\": psnr_vals, \"ssim\": ssim_vals}\n",
    "\n",
    "\n",
    "# --- PyTorch-based (for use during training) ---\n",
    "\n",
    "def psnr_torch(pred, gt, data_range=1.0):\n",
    "    \"\"\"\n",
    "    Compute PSNR using PyTorch tensors.\n",
    "    Returns scalar PSNR value (averaged over batch).\n",
    "    \"\"\"\n",
    "    mse = torch.mean((pred.float() - gt.float()) ** 2)\n",
    "    if mse.item() < 1e-10:\n",
    "        return torch.tensor(100.0)\n",
    "    return 10.0 * torch.log10(torch.tensor(data_range**2) / mse)\n",
    "\n",
    "\n",
    "def ssim_torch(pred, gt, window_size=11, data_range=1.0):\n",
    "    \"\"\"\n",
    "    Simple SSIM implementation in PyTorch using a Gaussian window.\n",
    "\n",
    "    Args:\n",
    "        pred: (B, 1, H, W) tensor\n",
    "        gt: (B, 1, H, W) tensor\n",
    "        window_size: Gaussian window size\n",
    "        data_range: max pixel value\n",
    "\n",
    "    Returns:\n",
    "        Scalar SSIM value\n",
    "    \"\"\"\n",
    "    C1 = (0.01 * data_range) ** 2\n",
    "    C2 = (0.03 * data_range) ** 2\n",
    "\n",
    "    # Create Gaussian window\n",
    "    sigma = 1.5\n",
    "    gauss = torch.Tensor(\n",
    "        [np.exp(-(x - window_size // 2) ** 2 / (2 * sigma**2)) for x in range(window_size)]\n",
    "    )\n",
    "    gauss = gauss / gauss.sum()\n",
    "\n",
    "    _1D_window = gauss.unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    window = _2D_window.expand(1, 1, window_size, window_size).contiguous()\n",
    "    window = window.to(pred.device).type(pred.dtype)\n",
    "\n",
    "    pad = window_size // 2\n",
    "\n",
    "    mu1 = torch.nn.functional.conv2d(pred, window, padding=pad, groups=1)\n",
    "    mu2 = torch.nn.functional.conv2d(gt, window, padding=pad, groups=1)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = torch.nn.functional.conv2d(pred * pred, window, padding=pad, groups=1) - mu1_sq\n",
    "    sigma2_sq = torch.nn.functional.conv2d(gt * gt, window, padding=pad, groups=1) - mu2_sq\n",
    "    sigma12 = torch.nn.functional.conv2d(pred * gt, window, padding=pad, groups=1) - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / (\n",
    "        (mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2)\n",
    "    )\n",
    "\n",
    "    return ssim_map.mean()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Checkpoint Management\n",
    "# ============================================================\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def save_checkpoint(\n",
    "    state,\n",
    "    checkpoint_dir,\n",
    "    epoch,\n",
    "    is_best=False,\n",
    "    prefix=\"mmgan\",\n",
    "    max_keep=3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save training checkpoint with metadata.\n",
    "\n",
    "    Saves to {prefix}_epoch_{epoch:04d}.pth, keeps only max_keep recent\n",
    "    checkpoints, and also saves best separately.\n",
    "    \"\"\"\n",
    "    ckpt_dir = Path(checkpoint_dir)\n",
    "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save epoch checkpoint\n",
    "    filename = ckpt_dir / f\"{prefix}_epoch_{epoch:04d}.pth\"\n",
    "    torch.save(state, filename)\n",
    "    print(f\"  [CKPT] Saved: {filename}\")\n",
    "\n",
    "    # Save latest pointer\n",
    "    latest_path = ckpt_dir / f\"{prefix}_latest.pth\"\n",
    "    torch.save(state, latest_path)\n",
    "\n",
    "    # Save best model\n",
    "    if is_best:\n",
    "        best_path = ckpt_dir / f\"{prefix}_best.pth\"\n",
    "        torch.save(state, best_path)\n",
    "        print(f\"  [CKPT] New best model saved!\")\n",
    "\n",
    "    # Save metadata\n",
    "    meta = {\n",
    "        \"epoch\": epoch,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"is_best\": is_best,\n",
    "        \"best_psnr\": state.get(\"best_psnr\", 0.0),\n",
    "        \"best_ssim\": state.get(\"best_ssim\", 0.0),\n",
    "    }\n",
    "    meta_path = ckpt_dir / f\"{prefix}_meta.json\"\n",
    "    with open(meta_path, \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    # Cleanup old checkpoints (keep latest N)\n",
    "    all_ckpts = sorted(glob.glob(str(ckpt_dir / f\"{prefix}_epoch_*.pth\")))\n",
    "    if len(all_ckpts) > max_keep:\n",
    "        for old_ckpt in all_ckpts[:-max_keep]:\n",
    "            os.remove(old_ckpt)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_dir, prefix=\"mmgan\", which=\"latest\"):\n",
    "    \"\"\"\n",
    "    Load a checkpoint.\n",
    "\n",
    "    Args:\n",
    "        checkpoint_dir: Directory containing checkpoints\n",
    "        prefix: Filename prefix\n",
    "        which: 'latest', 'best', or epoch number (int)\n",
    "\n",
    "    Returns:\n",
    "        state dict or None if not found\n",
    "    \"\"\"\n",
    "    ckpt_dir = Path(checkpoint_dir)\n",
    "\n",
    "    if isinstance(which, int):\n",
    "        path = ckpt_dir / f\"{prefix}_epoch_{which:04d}.pth\"\n",
    "    elif which == \"best\":\n",
    "        path = ckpt_dir / f\"{prefix}_best.pth\"\n",
    "    else:\n",
    "        path = ckpt_dir / f\"{prefix}_latest.pth\"\n",
    "\n",
    "    if not path.exists():\n",
    "        print(f\"  [CKPT] No checkpoint found at: {path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"  [CKPT] Loading: {path}\")\n",
    "    state = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
    "    return state\n",
    "\n",
    "\n",
    "def resume_training(\n",
    "    generator, discriminator,\n",
    "    optimizer_G, optimizer_D,\n",
    "    checkpoint_dir, prefix=\"mmgan\",\n",
    "    scheduler_G=None, scheduler_D=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Resume training from latest checkpoint.\n",
    "\n",
    "    Returns:\n",
    "        start_epoch: Epoch to resume from (0 if no checkpoint)\n",
    "        best_psnr: Best PSNR so far\n",
    "        best_ssim: Best SSIM so far\n",
    "        history: Training history dict\n",
    "    \"\"\"\n",
    "    state = load_checkpoint(checkpoint_dir, prefix, which=\"latest\")\n",
    "\n",
    "    if state is None:\n",
    "        return 0, 0.0, 0.0, {\"train_loss_G\": [], \"train_loss_D\": [], \"val_psnr\": [], \"val_ssim\": []}\n",
    "\n",
    "    # Restore model states\n",
    "    generator.load_state_dict(state[\"generator_state_dict\"])\n",
    "    discriminator.load_state_dict(state[\"discriminator_state_dict\"])\n",
    "    optimizer_G.load_state_dict(state[\"optimizer_G_state_dict\"])\n",
    "    optimizer_D.load_state_dict(state[\"optimizer_D_state_dict\"])\n",
    "\n",
    "    if scheduler_G is not None and \"scheduler_G_state_dict\" in state:\n",
    "        scheduler_G.load_state_dict(state[\"scheduler_G_state_dict\"])\n",
    "    if scheduler_D is not None and \"scheduler_D_state_dict\" in state:\n",
    "        scheduler_D.load_state_dict(state[\"scheduler_D_state_dict\"])\n",
    "\n",
    "    # Restore RNG states for reproducibility\n",
    "    if \"rng_state\" in state:\n",
    "        torch.set_rng_state(state[\"rng_state\"])\n",
    "    if \"numpy_rng_state\" in state:\n",
    "        np.random.set_state(state[\"numpy_rng_state\"])\n",
    "\n",
    "    start_epoch = state[\"epoch\"] + 1\n",
    "    best_psnr = state.get(\"best_psnr\", 0.0)\n",
    "    best_ssim = state.get(\"best_ssim\", 0.0)\n",
    "\n",
    "    history = state.get(\"history\", {\n",
    "        \"train_loss_G\": [], \"train_loss_D\": [],\n",
    "        \"val_psnr\": [], \"val_ssim\": [],\n",
    "    })\n",
    "\n",
    "    print(f\"  [CKPT] Resuming from epoch {start_epoch}\")\n",
    "    print(f\"  [CKPT] Best PSNR: {best_psnr:.4f}, Best SSIM: {best_ssim:.4f}\")\n",
    "\n",
    "    return start_epoch, best_psnr, best_ssim, history\n",
    "\n",
    "\n",
    "def build_checkpoint_state(\n",
    "    epoch, generator, discriminator,\n",
    "    optimizer_G, optimizer_D,\n",
    "    best_psnr, best_ssim, history,\n",
    "    scheduler_G=None, scheduler_D=None,\n",
    "):\n",
    "    \"\"\"Build a checkpoint state dict.\"\"\"\n",
    "    state = {\n",
    "        \"epoch\": epoch,\n",
    "        \"generator_state_dict\": generator.state_dict(),\n",
    "        \"discriminator_state_dict\": discriminator.state_dict(),\n",
    "        \"optimizer_G_state_dict\": optimizer_G.state_dict(),\n",
    "        \"optimizer_D_state_dict\": optimizer_D.state_dict(),\n",
    "        \"best_psnr\": best_psnr,\n",
    "        \"best_ssim\": best_ssim,\n",
    "        \"history\": history,\n",
    "        \"rng_state\": torch.get_rng_state(),\n",
    "        \"numpy_rng_state\": np.random.get_state(),\n",
    "    }\n",
    "\n",
    "    if scheduler_G is not None:\n",
    "        state[\"scheduler_G_state_dict\"] = scheduler_G.state_dict()\n",
    "    if scheduler_D is not None:\n",
    "        state[\"scheduler_D_state_dict\"] = scheduler_D.state_dict()\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "print(\"Metrics and checkpoint utilities loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Training loop with:\n",
    "- **Curriculum Learning**: Gradually introduces harder missing-modality scenarios.\n",
    "- **Implicit Conditioning**: Copies real available modalities into generator output.\n",
    "- **Session Time Management**: Monitors elapsed time and saves checkpoint before Kaggle's 2-hour limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION_START = time.time()\n",
    "\n",
    "\n",
    "def time_remaining():\n",
    "    \"\"\"Check remaining session time.\"\"\"\n",
    "    elapsed = time.time() - SESSION_START\n",
    "    return MAX_SESSION_TIME - elapsed\n",
    "\n",
    "\n",
    "def validate(generator, val_loader, device, scenarios=None):\n",
    "    \"\"\"Run validation and compute PSNR/SSIM metrics.\"\"\"\n",
    "    generator.eval()\n",
    "    if scenarios is None:\n",
    "        scenarios = ALL_SCENARIOS_3MOD\n",
    "    all_psnr, all_ssim = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_real = batch[\"image\"].to(device)\n",
    "            for scenario in scenarios:\n",
    "                x_input = impute_missing(x_real, scenario, impute_type=\"zeros\")\n",
    "                fake_x = generator(x_input)\n",
    "                fake_x = impute_reals_into_fake(x_real, fake_x, scenario)\n",
    "                for idx, available in enumerate(scenario):\n",
    "                    if available == 0:\n",
    "                        pred = fake_x[:, idx:idx+1, ...]\n",
    "                        gt = x_real[:, idx:idx+1, ...]\n",
    "                        all_psnr.append(psnr_torch(pred, gt).item())\n",
    "                        all_ssim.append(ssim_torch(pred, gt).item())\n",
    "    generator.train()\n",
    "    return np.mean(all_psnr) if all_psnr else 0.0, np.mean(all_ssim) if all_ssim else 0.0\n",
    "\n",
    "\n",
    "def train_one_epoch(generator, discriminator, optimizer_G, optimizer_D,\n",
    "                    train_loader, device, criterion_GAN, criterion_pixel,\n",
    "                    lambda_pixel, epoch, n_epochs, impute_type, use_ic, use_curriculum,\n",
    "                    writer=None, global_step=0):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    epoch_loss_G, epoch_loss_D, n_batches = 0.0, 0.0, 0\n",
    "\n",
    "    if use_curriculum:\n",
    "        low, high = get_curriculum_scenarios(epoch, n_epochs)\n",
    "        available_scenarios = ALL_SCENARIOS_3MOD[low:high]\n",
    "    else:\n",
    "        available_scenarios = ALL_SCENARIOS_3MOD\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}/{n_epochs}\", leave=False):\n",
    "        # Check time\n",
    "        if time_remaining() < 300:  # Less than 5 min left\n",
    "            print(f\"WARNING: Less than 5 min remaining, stopping epoch early\")\n",
    "            break\n",
    "\n",
    "        x_real = batch[\"image\"].to(device)\n",
    "        scenario = random.choice(available_scenarios)\n",
    "        x_input = impute_missing(x_real, scenario, impute_type=impute_type)\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_x = generator(x_input)\n",
    "        if use_ic:\n",
    "            fake_x_ic = impute_reals_into_fake(x_real, fake_x, scenario)\n",
    "        else:\n",
    "            fake_x_ic = fake_x\n",
    "        pred_fake = discriminator(fake_x_ic, x_real)\n",
    "        valid = torch.ones_like(pred_fake, device=device)\n",
    "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "        if use_ic:\n",
    "            loss_pixel = compute_missing_loss(fake_x_ic, x_real, scenario, criterion_pixel)\n",
    "        else:\n",
    "            loss_pixel = criterion_pixel(fake_x, x_real)\n",
    "        loss_G = (1 - lambda_pixel) * loss_GAN + lambda_pixel * loss_pixel\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        pred_real = discriminator(x_real, x_real)\n",
    "        valid = torch.ones_like(pred_real, device=device)\n",
    "        loss_real = criterion_GAN(pred_real, valid)\n",
    "        pred_fake = discriminator(fake_x_ic.detach(), x_real)\n",
    "        fake_label = torch.zeros_like(pred_fake, device=device)\n",
    "        loss_fake = criterion_GAN(pred_fake, fake_label)\n",
    "        loss_D = 0.5 * (loss_real + loss_fake)\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        epoch_loss_G += loss_G.item()\n",
    "        epoch_loss_D += loss_D.item()\n",
    "        n_batches += 1\n",
    "        global_step += 1\n",
    "\n",
    "        if writer and n_batches % 50 == 0:\n",
    "            writer.add_scalar(\"train/loss_G\", loss_G.item(), global_step)\n",
    "            writer.add_scalar(\"train/loss_D\", loss_D.item(), global_step)\n",
    "\n",
    "    return epoch_loss_G / max(n_batches, 1), epoch_loss_D / max(n_batches, 1), global_step\n",
    "\n",
    "\n",
    "print(\"Training functions loaded.\")\n",
    "print(f\"Session time remaining: {time_remaining():.0f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Training Loop\n",
    "\n",
    "Auto-resumes from checkpoint if available. If the session time limit approaches, training stops and saves a checkpoint. Re-run this notebook to continue from where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "set_seed(SEED)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Data\n",
    "print(\"Loading data...\")\n",
    "loaders = create_dataloaders(\n",
    "    data_dir=DATA_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    num_workers=2,\n",
    "    augment_train=True,\n",
    ")\n",
    "train_loader = loaders[\"train\"]\n",
    "val_loader = loaders.get(\"val\", None)\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "if val_loader:\n",
    "    print(f\"Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Models\n",
    "print(\"Building models...\")\n",
    "generator = GeneratorUNet(in_channels=IN_CHANNELS, out_channels=IN_CHANNELS).to(device)\n",
    "discriminator = Discriminator(in_channels=IN_CHANNELS, out_channels=IN_CHANNELS).to(device)\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=LR_G, betas=(BETA1, BETA2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=LR_D, betas=(BETA1, BETA2))\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=20, gamma=0.5)\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=20, gamma=0.5)\n",
    "\n",
    "# Loss\n",
    "criterion_GAN = nn.MSELoss().to(device)\n",
    "criterion_pixel = nn.L1Loss().to(device)\n",
    "\n",
    "# Resume?\n",
    "start_epoch = 0\n",
    "best_psnr, best_ssim = 0.0, 0.0\n",
    "history = {\"train_loss_G\": [], \"train_loss_D\": [], \"val_psnr\": [], \"val_ssim\": []}\n",
    "\n",
    "existing_ckpt = load_checkpoint(CHECKPOINT_DIR)\n",
    "if existing_ckpt is not None:\n",
    "    print(\"Resuming from checkpoint...\")\n",
    "    start_epoch, best_psnr, best_ssim, history = resume_training(\n",
    "        generator, discriminator, optimizer_G, optimizer_D,\n",
    "        CHECKPOINT_DIR, scheduler_G=scheduler_G, scheduler_D=scheduler_D,\n",
    "    )\n",
    "    print(f\"Resumed from epoch {start_epoch}, best PSNR: {best_psnr:.2f}\")\n",
    "else:\n",
    "    print(\"Starting fresh training\")\n",
    "\n",
    "# TensorBoard\n",
    "writer = SummaryWriter(LOG_DIR)\n",
    "\n",
    "# Training loop\n",
    "print(\"=\" * 60)\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Epochs: {start_epoch} -> {N_EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}, Lambda: {LAMBDA_PIXEL}\")\n",
    "print(f\"IC: {USE_IC}, Curriculum: {USE_CURRICULUM}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "global_step = start_epoch * len(train_loader)\n",
    "training_start = time.time()\n",
    "\n",
    "for epoch in range(start_epoch, N_EPOCHS):\n",
    "    # Check session time\n",
    "    if time_remaining() < 600:  # Less than 10 min\n",
    "        print(f\"\\nSession time limit approaching ({time_remaining():.0f}s remaining). Saving and stopping.\")\n",
    "        state = build_checkpoint_state(\n",
    "            epoch, generator, discriminator, optimizer_G, optimizer_D,\n",
    "            best_psnr, best_ssim, history, scheduler_G, scheduler_D,\n",
    "        )\n",
    "        save_checkpoint(state, CHECKPOINT_DIR, epoch, is_best=False)\n",
    "        break\n",
    "\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    avg_loss_G, avg_loss_D, global_step = train_one_epoch(\n",
    "        generator, discriminator, optimizer_G, optimizer_D,\n",
    "        train_loader, device, criterion_GAN, criterion_pixel,\n",
    "        LAMBDA_PIXEL, epoch, N_EPOCHS, IMPUTE_TYPE, USE_IC, USE_CURRICULUM,\n",
    "        writer=writer, global_step=global_step,\n",
    "    )\n",
    "\n",
    "    scheduler_G.step()\n",
    "    scheduler_D.step()\n",
    "\n",
    "    history[\"train_loss_G\"].append(avg_loss_G)\n",
    "    history[\"train_loss_D\"].append(avg_loss_D)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"Epoch [{epoch+1}/{N_EPOCHS}] Loss_G: {avg_loss_G:.4f} | Loss_D: {avg_loss_D:.4f} | Time: {epoch_time:.1f}s\")\n",
    "\n",
    "    # Validation\n",
    "    if val_loader and (epoch + 1) % VAL_INTERVAL == 0:\n",
    "        avg_psnr, avg_ssim = validate(generator, val_loader, device)\n",
    "        history[\"val_psnr\"].append(avg_psnr)\n",
    "        history[\"val_ssim\"].append(avg_ssim)\n",
    "        writer.add_scalar(\"val/psnr\", avg_psnr, epoch)\n",
    "        writer.add_scalar(\"val/ssim\", avg_ssim, epoch)\n",
    "        print(f\"  Val PSNR: {avg_psnr:.4f} | Val SSIM: {avg_ssim:.4f}\")\n",
    "        is_best = avg_psnr > best_psnr\n",
    "        if is_best:\n",
    "            best_psnr = avg_psnr\n",
    "            best_ssim = avg_ssim\n",
    "    else:\n",
    "        is_best = False\n",
    "\n",
    "    # Save checkpoint\n",
    "    if (epoch + 1) % SAVE_INTERVAL == 0 or is_best or (epoch + 1) == N_EPOCHS:\n",
    "        state = build_checkpoint_state(\n",
    "            epoch, generator, discriminator, optimizer_G, optimizer_D,\n",
    "            best_psnr, best_ssim, history, scheduler_G, scheduler_D,\n",
    "        )\n",
    "        save_checkpoint(state, CHECKPOINT_DIR, epoch, is_best=is_best)\n",
    "\n",
    "total_time = time.time() - training_start\n",
    "writer.close()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SESSION COMPLETE\")\n",
    "print(f\"  Time this session: {total_time:.1f}s ({total_time/3600:.2f}h)\")\n",
    "print(f\"  Completed epochs: {epoch+1}/{N_EPOCHS}\")\n",
    "print(f\"  Best PSNR: {best_psnr:.4f}\")\n",
    "print(f\"  Best SSIM: {best_ssim:.4f}\")\n",
    "print(f\"  Checkpoints: {CHECKPOINT_DIR}\")\n",
    "if epoch + 1 < N_EPOCHS:\n",
    "    print(f\"\\n  >>> Re-run this notebook to continue training from epoch {epoch+1} <<<\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Run this section **after all training epochs are complete**. Loads the best model checkpoint and evaluates on the test set across all 6 missing modality scenarios.\n",
    "\n",
    "Produces a per-scenario metrics table (PSNR, SSIM) and saves results to `metrics.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this after training is complete!\n",
    "print(\"Loading best model for evaluation...\")\n",
    "\n",
    "# Load best checkpoint\n",
    "generator_eval = GeneratorUNet(in_channels=IN_CHANNELS, out_channels=IN_CHANNELS).to(device)\n",
    "best_ckpt = load_checkpoint(CHECKPOINT_DIR, which=\"best\")\n",
    "if best_ckpt is None:\n",
    "    best_ckpt = load_checkpoint(CHECKPOINT_DIR, which=\"latest\")\n",
    "generator_eval.load_state_dict(best_ckpt[\"generator_state_dict\"])\n",
    "print(f\"Loaded checkpoint from epoch {best_ckpt.get('epoch', '?')}\")\n",
    "\n",
    "# Load test data\n",
    "test_loader = loaders.get(\"test\", None)\n",
    "if test_loader is None:\n",
    "    print(\"No test split found, using validation set\")\n",
    "    test_loader = val_loader\n",
    "\n",
    "# Evaluate\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "generator_eval.eval()\n",
    "results = {}\n",
    "with torch.no_grad():\n",
    "    for scenario in ALL_SCENARIOS_3MOD:\n",
    "        scenario_str = \"\".join(str(s) for s in scenario)\n",
    "        missing_mods = [MODALITY_NAMES[i] for i, s in enumerate(scenario) if s == 0]\n",
    "        avail_mods = [MODALITY_NAMES[i] for i, s in enumerate(scenario) if s == 1]\n",
    "        psnr_list, ssim_list = [], []\n",
    "        for batch in tqdm(test_loader, desc=f\"Eval {scenario_str}\", leave=False):\n",
    "            x_real = batch[\"image\"].to(device)\n",
    "            x_input = impute_missing(x_real, scenario, impute_type=\"zeros\")\n",
    "            fake_x = generator_eval(x_input)\n",
    "            fake_x = impute_reals_into_fake(x_real, fake_x, scenario)\n",
    "            fake_np = fake_x.cpu().numpy()\n",
    "            real_np = x_real.cpu().numpy()\n",
    "            for b in range(x_real.size(0)):\n",
    "                for idx, avail in enumerate(scenario):\n",
    "                    if avail == 0:\n",
    "                        psnr_list.append(psnr_numpy(fake_np[b, idx], real_np[b, idx]))\n",
    "                        ssim_list.append(ssim_numpy(fake_np[b, idx], real_np[b, idx]))\n",
    "        results[scenario_str] = {\n",
    "            \"missing\": missing_mods, \"available\": avail_mods,\n",
    "            \"psnr_mean\": float(np.mean(psnr_list)), \"psnr_std\": float(np.std(psnr_list)),\n",
    "            \"ssim_mean\": float(np.mean(ssim_list)), \"ssim_std\": float(np.std(ssim_list)),\n",
    "            \"n_samples\": len(psnr_list),\n",
    "        }\n",
    "\n",
    "# Overall\n",
    "all_p = [v[\"psnr_mean\"] for v in results.values()]\n",
    "all_s = [v[\"ssim_mean\"] for v in results.values()]\n",
    "overall = {\"psnr_mean\": float(np.mean(all_p)), \"ssim_mean\": float(np.mean(all_s))}\n",
    "\n",
    "# Print table\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Results: {EXPERIMENT_NAME}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"{'Scenario':<12} {'Missing':<15} {'Available':<15} {'PSNR':>10} {'SSIM':>10}\")\n",
    "print(f\"{'-'*70}\")\n",
    "for key, val in results.items():\n",
    "    print(f\"{key:<12} {','.join(val['missing']):<15} {','.join(val['available']):<15} \"\n",
    "          f\"{val['psnr_mean']:>7.2f}+-{val['psnr_std']:.2f} \"\n",
    "          f\"{val['ssim_mean']:>7.4f}+-{val['ssim_std']:.4f}\")\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"{'OVERALL':<42} {overall['psnr_mean']:>7.2f}       {overall['ssim_mean']:>7.4f}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Save\n",
    "metrics_path = os.path.join(RESULTS_DIR, \"metrics.json\")\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump({\"per_scenario\": results, \"overall\": overall}, f, indent=2)\n",
    "print(f\"\\nMetrics saved to: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Artifacts\n",
    "\n",
    "Package checkpoints and results into a zip file for download. Use this to:\n",
    "- Transfer checkpoints to the next session (if training is not complete).\n",
    "- Download final results for comparison between baseline and optimized experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package artifacts for download\n",
    "import shutil\n",
    "artifact_name = f\"mmgan_{EXPERIMENT_NAME}_artifacts\"\n",
    "shutil.make_archive(\n",
    "    f\"/kaggle/working/{artifact_name}\",\n",
    "    \"zip\",\n",
    "    \"/kaggle/working\",\n",
    "    \".\"\n",
    ")\n",
    "print(f\"Artifacts packaged: /kaggle/working/{artifact_name}.zip\")\n",
    "print(\"Download this file from the Output tab before session ends!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "version": "3.10.12"
  },
  "nbformat": 4,
  "nbformat_minor": 4
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
